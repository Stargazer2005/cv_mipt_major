{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Homework 5"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Задача №1 - Можете ли вы отличить сорняки от рассады?\n",
            "\n",
            "Теперь приступим к задаче классификации на картинках. Реализуйте программу, которая определяет тип рассады на изображении. \n",
            "\n",
            "Для того, чтобы определить характерные особенности каждого типа рассады, у вас есть train. Train это папка, в которой картинки уже классифицированы и лежат в соответствующих папках. Исходя из этой информации можете найти признаки, присущие конкретному растению.\n",
            "\n",
            "Проверка вашего решения будет на происходить на test. В папке test уже нет метки класса для каждой картинки. \n",
            "\n",
            "[Ссылка на Яндекс-диск](https://yadi.sk/d/0Zzp0klXT0iRmA), все картинки тут.\n",
            "\n",
            "Примеры изображений для теста:\n",
            "<table><tr>\n",
            "    <td> <img src=\"https://i.ibb.co/tbqR37m/fhj.png\" alt=\"Drawing\" style=\"width: 200px;\"/> </td>\n",
            "    <td> <img src=\"https://i.ibb.co/6yL3Wmt/sfg.png\" alt=\"Drawing\" style=\"width: 200px;\"/> </td>\n",
            "    <td> <img src=\"https://i.ibb.co/pvn7NvF/asd.png\" alt=\"Drawing\" style=\"width: 200px;\"/> </td>\n",
            "</tr></table>"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "\"\"\"Plant species classification using SIFT features and Bag of Visual Words.\"\"\"\n",
            "\n",
            "import os\n",
            "from glob import glob\n",
            "from typing import List, Dict, Tuple, Any, Optional\n",
            "\n",
            "import cv2\n",
            "import numpy as np\n",
            "from sklearn.cluster import KMeans\n",
            "from sklearn.pipeline import Pipeline\n",
            "from sklearn.preprocessing import StandardScaler\n",
            "from sklearn.linear_model import LogisticRegression\n",
            "from sklearn.metrics import accuracy_score\n",
            "from tqdm import tqdm\n",
            "\n",
            "\n",
            "def GetSIFTDescriptors(image_path: str) -> Optional[np.ndarray]:\n",
            "    \"\"\"Extracts SIFT descriptors from an image with green plant masking.\n",
            "    \n",
            "    Args:\n",
            "        image_path: Path to the input image.\n",
            "    \n",
            "    Returns:\n",
            "        Numpy array of SIFT descriptors (N x 128) or None if no features found.\n",
            "    \"\"\"\n",
            "    img = cv2.imread(image_path, cv2.IMREAD_COLOR_RGB)\n",
            "    if img is None:\n",
            "        return None\n",
            "\n",
            "    img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
            "    mask = cv2.inRange(img_hsv, (35, 50, 50), (85, 255, 255))\n",
            "    gray_img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) * mask\n",
            "\n",
            "    sift = cv2.SIFT_create()\n",
            "    _, descriptors = sift.detectAndCompute(gray_img, None)\n",
            "    \n",
            "    return descriptors\n",
            "\n",
            "\n",
            "def BuildFeatureVocabulary(\n",
            "    train_image_paths: List[str],\n",
            "    feature_size: int,\n",
            "    random_state: int = 42\n",
            ") -> KMeans:\n",
            "    \"\"\"Builds visual vocabulary using K-means clustering on SIFT features.\n",
            "    \n",
            "    Args:\n",
            "        train_image_paths: List of paths to training images.\n",
            "        feature_size: Number of clusters for K-means.\n",
            "        random_state: Random seed for reproducibility.\n",
            "    \n",
            "    Returns:\n",
            "        Trained KMeans model representing the visual vocabulary.\n",
            "    \"\"\"\n",
            "    all_descriptors = []\n",
            "\n",
            "    for path in tqdm(train_image_paths, desc=\"Extracting SIFT features\"):\n",
            "        descriptors = GetSIFTDescriptors(path)\n",
            "        if descriptors is not None:\n",
            "            all_descriptors.append(descriptors)\n",
            "\n",
            "    if not all_descriptors:\n",
            "        raise ValueError(\"No SIFT descriptors found in training images.\")\n",
            "\n",
            "    all_descriptors = np.vstack(all_descriptors)\n",
            "    kmeans = KMeans(n_clusters=feature_size, random_state=random_state)\n",
            "    kmeans.fit(all_descriptors)\n",
            "    \n",
            "    return kmeans\n",
            "\n",
            "\n",
            "def CreateFeatureArray(\n",
            "    image_path: str,\n",
            "    kmeans: KMeans,\n",
            "    feature_size: int\n",
            ") -> np.ndarray:\n",
            "    \"\"\"Creates a feature array (histogram) for an image using visual words.\n",
            "    \n",
            "    Args:\n",
            "        image_path: Path to the input image.\n",
            "        kmeans: Trained KMeans model for visual words.\n",
            "        feature_size: Number of visual words.\n",
            "    \n",
            "    Returns:\n",
            "        Normalized histogram of visual words (feature array).\n",
            "    \"\"\"\n",
            "    descriptors = GetSIFTDescriptors(image_path)\n",
            "    if descriptors is None:\n",
            "        return np.zeros(feature_size)\n",
            "\n",
            "    visual_words = kmeans.predict(descriptors)\n",
            "    hist, _ = np.histogram(visual_words, bins=feature_size, range=(0, feature_size))\n",
            "    hist = hist.astype(np.float32)\n",
            "\n",
            "    if hist.sum() != 0:\n",
            "        hist /= hist.sum()\n",
            "    \n",
            "    return hist\n",
            "\n",
            "\n",
            "def LoadImagePathsAndLabels(\n",
            "    data_dir: str\n",
            ") -> Tuple[List[str], List[int], List[str]]:\n",
            "    \"\"\"Loads image paths and corresponding labels from directory structure.\n",
            "    \n",
            "    Args:\n",
            "        data_dir: Directory containing subdirectories for each class.\n",
            "    \n",
            "    Returns:\n",
            "        Tuple of (image_paths, labels, class_names)\n",
            "    \"\"\"\n",
            "    class_names = sorted(os.listdir(data_dir))\n",
            "    image_paths = []\n",
            "    labels = []\n",
            "\n",
            "    for label, class_name in enumerate(class_names):\n",
            "        class_path = os.path.join(data_dir, class_name)\n",
            "        for img_path in glob(os.path.join(class_path, \"*.png\")):\n",
            "            image_paths.append(img_path)\n",
            "            labels.append(label)\n",
            "    \n",
            "    return image_paths, labels, class_names\n",
            "\n",
            "\n",
            "def TrainPlantClassifier(\n",
            "    train_dir: str,\n",
            "    feature_size: int = 100,\n",
            "    random_state: int = 42\n",
            ") -> Tuple[Pipeline, KMeans, List[str]]:\n",
            "    \"\"\"Trains a plant species classifier using SIFT and BoVW approach.\n",
            "    \n",
            "    Args:\n",
            "        train_dir: Directory containing training images.\n",
            "        feature_size: Number of visual words.\n",
            "        random_state: Random seed for reproducibility.\n",
            "    \n",
            "    Returns:\n",
            "        Tuple of (trained classifier, visual vocabulary, class names)\n",
            "    \"\"\"\n",
            "    print(\"=== Loading training data ===\")\n",
            "    train_image_paths, train_labels, class_names = LoadImagePathsAndLabels(train_dir)\n",
            "\n",
            "    print(\"\\n=== Building visual vocabulary ===\")\n",
            "    kmeans = BuildFeatureVocabulary(train_image_paths, feature_size, random_state)\n",
            "\n",
            "    print(\"\\n=== Creating training features ===\")\n",
            "    x_train = []\n",
            "    for path in tqdm(train_image_paths, desc=\"Processing training images\"):\n",
            "        feature_vector = CreateFeatureArray(path, kmeans, feature_size)\n",
            "        x_train.append(feature_vector)\n",
            "    \n",
            "    x_train = np.array(x_train)\n",
            "    y_train = np.array(train_labels)\n",
            "\n",
            "    print(\"\\n=== Training classifier ===\")\n",
            "    classifier = Pipeline([\n",
            "        ('scaler', StandardScaler()),\n",
            "        ('classifier', LogisticRegression(random_state=random_state))\n",
            "    ])\n",
            "    classifier.fit(x_train, y_train)\n",
            "    print(\"\\n=== Training finished ===\")\n",
            "    return classifier, kmeans, class_names\n",
            "\n",
            "\n",
            "def TestPlantClassifier(\n",
            "    test_dir: str,\n",
            "    classifier: Pipeline,\n",
            "    kmeans: KMeans,\n",
            "    class_names: List[str],\n",
            "    feature_size: int\n",
            ") -> Tuple[List[Dict[str, Any]], List[int]]:\n",
            "    \"\"\"Tests the trained plant classifier on new images.\n",
            "    \n",
            "    Args:\n",
            "        test_dir: Directory containing test images.\n",
            "        classifier: Trained classifier pipeline.\n",
            "        kmeans: Trained visual vocabulary.\n",
            "        class_names: List of class names.\n",
            "        feature_size: Number of visual words.\n",
            "    \n",
            "    Returns:\n",
            "        Tuple of (detailed results, predicted labels)\n",
            "    \"\"\"\n",
            "    test_image_paths = glob(os.path.join(test_dir, \"*.png\"))\n",
            "    results = []\n",
            "    predictions = []\n",
            "\n",
            "    print(f\"\\n=== Testing on {len(test_image_paths)} images ===\")\n",
            "    for img_path in tqdm(test_image_paths, desc=\"Processing test images\"):\n",
            "        feature_vector = CreateFeatureArray(img_path, kmeans, feature_size)\n",
            "        probabilities = classifier.predict_proba([feature_vector])[0]\n",
            "        \n",
            "        top_class_idx = np.argmax(probabilities)\n",
            "        top_class_name = class_names[top_class_idx]\n",
            "        top_confidence = probabilities[top_class_idx]\n",
            "\n",
            "        predictions.append(top_class_idx)\n",
            "        results.append({\n",
            "            'image_path': img_path,\n",
            "            'predictions': list(zip(class_names, probabilities)),\n",
            "            'top_class': top_class_name,\n",
            "            'top_class_idx': top_class_idx,\n",
            "            'confidence': top_confidence\n",
            "        })\n",
            "    \n",
            "    return results, predictions\n",
            "\n",
            "\n",
            "def PrintTestResults(\n",
            "    test_results: List[Dict[str, Any]],\n",
            "    y_true: List[int],\n",
            "    y_pred: List[int],\n",
            "    is_detailed: bool\n",
            ") -> None:\n",
            "    \"\"\"Prints test results and evaluation metrics.\n",
            "    \n",
            "    Args:\n",
            "        test_results: Detailed prediction results.\n",
            "        y_true: Ground truth labels.\n",
            "        y_pred: Predicted labels.\n",
            "        is_detailed: Detailed Results Or Not.\n",
            "    \"\"\"\n",
            "    if(is_detailed):\n",
            "        print(\"\\n=== Detailed Test Results ===\")\n",
            "        for result in test_results:\n",
            "            print(f\"\\nImage: {os.path.basename(result['image_path'])}\")\n",
            "            print(f\"Predicted: {result['top_class']} (confidence: {result['confidence']:.2f})\")\n",
            "            print(\"Class probabilities:\")\n",
            "            for class_name, prob in sorted(result['predictions'], key=lambda x: -x[1]):\n",
            "                print(f\"  {class_name}: {prob:.4f}\")\n",
            "\n",
            "    print(\"\\n=== Evaluation Metrics ===\")\n",
            "    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "=== Loading training data ===\n"
               ]
            },
            {
               "ename": "FileNotFoundError",
               "evalue": "[WinError 3] Системе не удается найти указанный путь: 'plants\\\\train'",
               "output_type": "error",
               "traceback": [
                  "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                  "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
                  "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      7\u001b[39m y_test = np.array([\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m, \n\u001b[32m      8\u001b[39m         \u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m])\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m classifier, visual_vocab, class_names = \u001b[43mTrainPlantClassifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n",
                  "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 141\u001b[39m, in \u001b[36mTrainPlantClassifier\u001b[39m\u001b[34m(train_dir, feature_size, random_state)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Trains a plant species classifier using SIFT and BoVW approach.\u001b[39;00m\n\u001b[32m    131\u001b[39m \n\u001b[32m    132\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    138\u001b[39m \u001b[33;03m    Tuple of (trained classifier, visual vocabulary, class names)\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    140\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== Loading training data ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m train_image_paths, train_labels, class_names = \u001b[43mLoadImagePathsAndLabels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Building visual vocabulary ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    144\u001b[39m kmeans = BuildFeatureVocabulary(train_image_paths, feature_size, random_state)\n",
                  "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 112\u001b[39m, in \u001b[36mLoadImagePathsAndLabels\u001b[39m\u001b[34m(data_dir)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mLoadImagePathsAndLabels\u001b[39m(\n\u001b[32m    102\u001b[39m     data_dir: \u001b[38;5;28mstr\u001b[39m\n\u001b[32m    103\u001b[39m ) -> Tuple[List[\u001b[38;5;28mstr\u001b[39m], List[\u001b[38;5;28mint\u001b[39m], List[\u001b[38;5;28mstr\u001b[39m]]:\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Loads image paths and corresponding labels from directory structure.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    110\u001b[39m \u001b[33;03m        Tuple of (image_paths, labels, class_names)\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     class_names = \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    113\u001b[39m     image_paths = []\n\u001b[32m    114\u001b[39m     labels = []\n",
                  "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] Системе не удается найти указанный путь: 'plants\\\\train'"
               ]
            }
         ],
         "source": [
            "train_dir = os.path.join(\"plants_data\", \"train\")\n",
            "test_dir = os.path.join(\"plants_data\", \"test\")\n",
            "feature_size = 100\n",
            "random_state = 42\n",
            "\n",
            "# Ground truth labels\n",
            "y_test = np.array([0, 0, 1, 1, 0, 0, 2, 3, 1, 0, 1, 1, 0, 3, 2, 3, 2, 3, 0, 3, \n",
            "        2, 2, 3, 1, 3, 2, 2, 1, 3, 3, 0, 2, 0, 0, 1, 2, 3, 2, 1, 1])\n",
            "\n",
            "# Train the model\n",
            "classifier, visual_vocab, class_names = TrainPlantClassifier(\n",
            "    train_dir, feature_size, random_state)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [
            {
               "ename": "NameError",
               "evalue": "name 'TestPlantClassifier' is not defined",
               "output_type": "error",
               "traceback": [
                  "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                  "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
                  "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Test the model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m test_results, y_pred = \u001b[43mTestPlantClassifier\u001b[49m(\n\u001b[32m      3\u001b[39m     test_dir, classifier, visual_vocab, class_names, feature_size)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[32m      6\u001b[39m PrintTestResults(test_results, y_test, y_pred, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
                  "\u001b[31mNameError\u001b[39m: name 'TestPlantClassifier' is not defined"
               ]
            }
         ],
         "source": [
            "# Test the model\n",
            "test_results, y_pred = TestPlantClassifier(\n",
            "    test_dir, classifier, visual_vocab, class_names, feature_size)\n",
            "\n",
            "# Print results\n",
            "PrintTestResults(test_results, y_test, y_pred, False)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Задача №2 - Собери пазл (2.0).\n",
            "\n",
            "Даны кусочки изображения, ваша задача склеить пазл в исходную картинку. \n",
            "\n",
            "Условия:\n",
            "* Дано исходное изображение для проверки, использовать собранное изображение в самом алгоритме нельзя;\n",
            "* Картинки имеют друг с другом пересечение;\n",
            "* После разрезки кусочки пазлов не были повернуты или отражены;\n",
            "* НЕЛЬЗЯ выбрать опорную картинку для сбора пазла, как это было в homework 3\n",
            "* В процессе проверки решения пазлы могут быть перемешаны, т.е. порядок пазлов в проверке может отличаться от исходного \n",
            "\n",
            "Изображения расположены по [ссылке](https://disk.yandex.ru/d/XtpawH1sV9UDlg).\n",
            "\n",
            "Примеры изображений:\n",
            "<img src=\"puzzle/su_fighter.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
            "<table><tr>\n",
            "    <td> <img src=\"puzzle/su_fighter_shuffle/0.jpg\" alt=\"Drawing\" style=\"width: 200px;\"/> </td>\n",
            "    <td> <img src=\"puzzle/su_fighter_shuffle/1.jpg\" alt=\"Drawing\" style=\"width: 200px;\"/> </td>\n",
            "    <td> <img src=\"puzzle/su_fighter_shuffle/2.jpg\" alt=\"Drawing\" style=\"width: 200px;\"/> </td>\n",
            "    <td> <img src=\"puzzle/su_fighter_shuffle/3.jpg\" alt=\"Drawing\" style=\"width: 200px;\"/> </td>\n",
            "</tr></table>"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Ваш код"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "hide_input": false,
      "kernelspec": {
         "display_name": "my-rdkit-env",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.13.0"
      },
      "toc": {
         "base_numbering": 1,
         "nav_menu": {},
         "number_sections": true,
         "sideBar": true,
         "skip_h1_title": false,
         "title_cell": "Table of Contents",
         "title_sidebar": "Contents",
         "toc_cell": false,
         "toc_position": {},
         "toc_section_display": true,
         "toc_window_display": false
      },
      "varInspector": {
         "cols": {
            "lenName": 16,
            "lenType": 16,
            "lenVar": 40
         },
         "kernels_config": {
            "python": {
               "delete_cmd_postfix": "",
               "delete_cmd_prefix": "del ",
               "library": "var_list.py",
               "varRefreshCmd": "print(var_dic_list())"
            },
            "r": {
               "delete_cmd_postfix": ") ",
               "delete_cmd_prefix": "rm(",
               "library": "var_list.r",
               "varRefreshCmd": "cat(var_dic_list()) "
            }
         },
         "types_to_exclude": [
            "module",
            "function",
            "builtin_function_or_method",
            "instance",
            "_Feature"
         ],
         "window_display": false
      }
   },
   "nbformat": 4,
   "nbformat_minor": 4
}
